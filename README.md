# tokenizer

[![travis][travis-image]][travis-url]
[![pypi][pypi-image]][pypi-url]

[travis-image]: https://img.shields.io/travis/Yoctol/tokenizer.svg?style=flat
[travis-url]: https://travis-ci.org/Yoctol/tokenizer
[pypi-image]: https://img.shields.io/pypi/v/tokenizer.svg?style=flat
[pypi-url]: https://pypi.python.org/pypi/tokenizer

yoctol 乂卍oO煞氣ㄟtokenizerOo卍乂

Tokenizers have the same interface of Jieba:

```python
tokenizer = Tokenizer()
tokenizer.lcut('我来到北京清华大学')
# ['我', '来到', '北京', '清华大学']
```
